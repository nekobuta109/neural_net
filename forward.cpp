#include "net.h"
const float * net::forward(const float input[])
{
	//==================================================
    //		input layer		[0]
	//==================================================
	//入力値は、a[],z[]ともに、 1 オリジンとします。wの添字0がバイアスとして使われている以上、
	//全部それに習わないといけません。
	//入力値 input[] は、0 オリジンとします。こうするしかないのかなあ・・
	//a[0],z[0]は不定です。一応０入れておきますか
	{
		a[0][0] = z[0][0]=0.0;	//使いませんが
		for(int i=1 ; i < n_units[0]+1 ; ++ i ){
	    	a[0][i]=z[0][i] = input[i-1];
		}
	}
	//==================================
    //		hidden layer	[1]-[L-2]
	//	と、output layer [L-1]の順伝播です。
	//==================================
	for(int l = 1; l < L; l++) {
		//各入力の値は、
		//今回のレイヤの入力値を決めていく。
		for(int j = 1; j < n_units[l]+1 ; ++j)	{		//これが対象となるニューロンユニットです。i->j
			a[l][j]=0.0;
			for(int i = 1 ; i < n_units[l-1]+1 ; ++i) {	//前段のユニット数分、重みをかけながら足していきます。
				a[l][j]	+=	w[l-1][i][j] * z[l-1][i];
			}
        }
		//zが、今回の活性化関数を書けた後の処理です。
		activator[l]->array_act(n_units[l] , a[l], z[l]);
	}
	//これで、最終段 z[L-1]が、ニューラルネットの答えとなります。
	//y[]にコピーして返します。
	for(int i=0 ; i< n_units[OUTPUT_LAYER]+1 ; ++i){
		y[i] = z[OUTPUT_LAYER][i];
	}
	return (const float*)y;
}
